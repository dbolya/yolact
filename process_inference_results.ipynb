{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/Actuate/slip-and-fall-offline-v2/e/SLIP-4\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/gpu_memory. Invalid point: 2022-01-12T16:53:44.273Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/cpu. Invalid point: 2022-01-12T16:53:44.273Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-01-12T16:53:44.273Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 38 operations to synchronize with Neptune. Do not kill this process.\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/stderr. Invalid point: 2022-01-12T16:54:10.072Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/stderr. Invalid point: 2022-01-12T16:54:10.098Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/cpu. Invalid point: 2022-01-12T16:53:54.281Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-01-12T16:53:54.281Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/gpu_memory. Invalid point: 2022-01-12T16:53:54.281Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 38 operations synced, thanks for waiting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/gpu_memory. Invalid point: 2022-01-12T16:54:14.096Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/cpu. Invalid point: 2022-01-12T16:54:14.096Z\n",
      "Error occurred during asynchronous operation processing: Timestamp must be non-decreasing for series attribute: monitoring/memory. Invalid point: 2022-01-12T16:54:14.096Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os, glob\n",
    "import neptune.new as neptune\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def del_empty(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return [del_empty(sub) for sub in lst if sub != []]\n",
    "    return lst\n",
    "\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "# Neptune.ai init\n",
    "run = neptune.init(\n",
    "    name = 'Slip and fall holdout set testing.',\n",
    "    description = 'Logging testing performance on resnet trained model for detecting slip and fall videos.',\n",
    "    custom_run_id = 'SLIP-3',\n",
    "    project=\"Actuate/slip-and-fall-offline-v2\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmYTljNWFlMi01Y2I4LTQwYTctOTNmOS0wNjc2ZjY0NGQ4MzAifQ==\", # Ajay's personal API token\n",
    "    source_files='*.py'\n",
    ")\n",
    "run['model_checkpoints/model'].upload('./weights/slip-fall-chosen-weights/yolact_resnet50_432_74900.pth') # Log current model on Neptune\n",
    "\n",
    "# Create ground truth file\n",
    "ground_truth = pd.read_csv('./datasets/slip-fall/ground-truths.csv', sep = '\\t')\n",
    "ground_truth['HUMAN DETS'] = np.where(ground_truth['Condition'] == 'Normal', 0, 1)\n",
    "ground_truth = ground_truth.drop(['Condition'], axis = 1)\n",
    "ground_truth = ground_truth.rename({'File ID': 'File'}, axis = 'columns')\n",
    "\n",
    "\n",
    "# Create fused detections dataframe \n",
    "basepath = './results/results_v3_transfer_learning/charts/'\n",
    "confidence_directories = sorted(os.listdir(basepath))\n",
    "super_list = []\n",
    "for directory in confidence_directories:\n",
    "    lists = [] \n",
    "    active_directory = os.path.join(basepath, directory)\n",
    "    files_to_parse = sorted(glob.glob(active_directory + '/*.csv'))\n",
    "    for file in files_to_parse:\n",
    "            parsed_confidence = os.path.dirname(file).split('/', 4)[4].split('-')[0:2]\n",
    "            addition = {'Confidence': '.'.join(parsed_confidence)}\n",
    "            df = pd.read_csv(file)\n",
    "            df = df.drop(df.columns[0], axis = 1)\n",
    "            try:\n",
    "                output_dictionary = df.groupby(['File']).agg(num_falls = ('Track ID', 'count')).reset_index().to_dict('records')\n",
    "            except KeyError:\n",
    "                output_dictionary = [{'File': os.path.basename(file).replace('.csv', '.mp4'), 'num_falls': 0}]\n",
    "            if len(output_dictionary) == 0:\n",
    "                output_dictionary = [{'File': os.path.basename(file).replace('.csv', '.mp4'), 'num_falls': 0}]\n",
    "            else:\n",
    "                pass\n",
    "            output_dictionary[0].update(addition)\n",
    "            lists.append(output_dictionary)\n",
    "    cleaned = del_empty(lists)\n",
    "    super_list.append(flatten(cleaned))\n",
    "df = pd.DataFrame(flatten(super_list))\n",
    "df = df.rename({'num_falls': 'Model Falls'}, axis = 'columns')\n",
    "df['MODEL DETS'] = np.where(df['Model Falls'] >= 1, 1, 0)\n",
    "df = df.merge(ground_truth, on = 'File')\n",
    "df['Confidence'] = pd.to_numeric(df['Confidence'])\n",
    "binary_detections = df.copy()\n",
    "binary_detections.to_csv(os.path.join(basepath, 'fused_results_table.csv'))\n",
    "run['tables/csv'].upload('./results/results_v3_transfer_learning/charts/fused_results_table.csv') # Log CSV file on Neptune\n",
    "\n",
    "# Create confusion Matrix\n",
    "values = []\n",
    "for conf, dataframe in binary_detections.groupby('Confidence'):\n",
    "    f1_value = f1_score(dataframe['HUMAN DETS'], dataframe['MODEL DETS'])\n",
    "    cm = confusion_matrix(dataframe['HUMAN DETS'], dataframe['MODEL DETS'], labels = [0, 1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = np.array([0, 1]))\n",
    "    f1,ax = plt.subplots(1, figsize = (5,5))\n",
    "    disp.plot(ax = ax)\n",
    "    ax.set(title = 'Confusion Matrix @ IOU: CF {}'.format(conf))\n",
    "    if not os.path.exists('./results/results_v3_transfer_learning/charts/confusion_matrix'):\n",
    "        os.makedirs('./results/results_v3_transfer_learning/charts/confusion_matrix')\n",
    "    f1.savefig('./results/results_v3_transfer_learning/charts/confusion_matrix/confusion_matrix_conf_{}.png'.format(conf))\n",
    "    run['metrics/confusion_matrix'].log(f1) # Upload confusion matricies\n",
    "    plt.close(f1)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    val = {'CONF': conf, \n",
    "            'TN': tn, \n",
    "            'FP': fp, \n",
    "            'FN': fn, \n",
    "            'TP': tp, \n",
    "            'F1': f1_value, \n",
    "            'TPR': tp / (tp + fn), \n",
    "            'P': tp / (tp + fp), \n",
    "            'R': tp / (tp + fn), \n",
    "            'FPR': fp / (fp + tn)}\n",
    "    values.append(val)\n",
    "metrics = pd.DataFrame(values)\n",
    "metrics.to_csv('./results/results_v3_transfer_learning/charts/summary_statistics.csv')\n",
    "run['metrics/summary_stats'].upload('./results/results_v3_transfer_learning/charts/summary_statistics.csv')\n",
    "run['metrics'] = metrics.sort_values(by = 'F1', ascending = False).dropna(inplace = False).head(1).to_dict('records')[0] # Upload best model parameters\n",
    "\n",
    "# Graph ROC\n",
    "f2, ax = plt.subplots(1, figsize = (9,7))\n",
    "ax.plot(metrics['FPR'].values, metrics['TPR'].values, color=np.random.rand(3,), lw=2)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label = 'YOLACT Base, AUC: {:.2f}'.format(auc(metrics['FPR'].values, metrics['TPR'].values)))\n",
    "ax.set(xlim = [0.0, 1.0], ylim = [0.0, 1.05], yticks = [i/10.0 for i in range(11)], xticks = [i/10.0 for i in range(11)], xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n",
    "ax.legend(loc = 'lower right')\n",
    "f2.savefig('./results/results_v3_transfer_learning/charts/roc_auc_curve.png') # Upload all ROC curves.\n",
    "run['roc_auc_curve'].upload(f2)\n",
    "plt.close(f2)\n",
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7997ca2cf6f82a32cba4455fba40e779da088b6fcef0f47d94689f04f3d2f0e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('YOLACT': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
