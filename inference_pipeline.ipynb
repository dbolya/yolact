{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Slip and Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = 1.5\n",
    "__author__ = 'Ajay Bhargava'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import VideoReaders, DetectorLoader\n",
    "import numpy as np, pandas as pd, glob\n",
    "import cv2\n",
    "from skimage import measure, color\n",
    "from SORT.sort import *\n",
    "import warnings\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedAssignment:\n",
    "    def __init__(self, chained=None):\n",
    "        acceptable = [None, 'warn', 'raise']\n",
    "        assert chained in acceptable, \"chained must be in \" + str(acceptable)\n",
    "        self.swcw = chained\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.saved_swcw = pd.options.mode.chained_assignment\n",
    "        pd.options.mode.chained_assignment = self.swcw\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        pd.options.mode.chained_assignment = self.saved_swcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model = DetectorLoader.YOLACT('./weights/yolact_resnet50_54_800000.pth', threshold = 0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fall(path):\n",
    "    '''\n",
    "    Docstring for detect_slip_fall()\n",
    "\n",
    "    Arguments\n",
    "    -----------\n",
    "    str(path): Takes a path and sends it to the function for inference and subsequent action\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    output(dict): A dictionary with the output of the model {\"Frame\": frame, \"BBOX\": bbox} \n",
    "    which is the first frame and person position where the person fell down. \n",
    "    '''\n",
    "\n",
    "    frame_provider = VideoReaders.VideoReader(path)\n",
    "    length, shape = frame_provider.properties()\n",
    "\n",
    "    output_inference = []\n",
    "    frames = []\n",
    "\n",
    "    for frame in frame_provider:\n",
    "        frames.append(frame)\n",
    "        c, s, bb, ma = model.predict(frame)\n",
    "        idx = np.where(c == 0)\n",
    "        pixelwise_arrays = []\n",
    "        for item in idx:\n",
    "            for n, qq in enumerate(item):\n",
    "                pixelwise = np.zeros_like(ma[qq,...])\n",
    "                pixelwise = ma[qq,...].astype(np.uint8)\n",
    "                pixelwise[np.where(pixelwise == 1)] = n + 1\n",
    "                pixelwise_arrays.append(pixelwise)\n",
    "\n",
    "        filtered = []\n",
    "        for array in pixelwise_arrays:\n",
    "            if np.max(array) != 0:\n",
    "                filtered.append(array)\n",
    "\n",
    "        stacked = np.sum(filtered, axis = 0)\n",
    "        output_inference.append(stacked)\n",
    "\n",
    "    output = []\n",
    "    for arry in output_inference:\n",
    "        if len(arry.shape) < 2:\n",
    "            output.append(np.zeros(shape).astype(np.uint8))\n",
    "        else:\n",
    "            output.append(arry)\n",
    "    \n",
    "    if len(output) != len(frames):\n",
    "        raise ValueError(\"Frame Lengths are off.\")\n",
    "\n",
    "    minimal_dictionary = []\n",
    "    for i in range(0, length):\n",
    "        for region in measure.regionprops(output[i], color.rgb2gray(frames[i])):\n",
    "            minimal_dictionary.append({\n",
    "                \"Frame\": i, \n",
    "                \"ID\": region.label, \n",
    "                \"BBOX\": region.bbox\n",
    "            })\n",
    "\n",
    "    tracked_bboxes = []\n",
    "    Sorter = Sort(max_age = length, min_hits = 1, iou_threshold = 0.01) # 1 Tunable parameter (iou_threshold)\n",
    "    for instance, entry in groupby(minimal_dictionary, key = lambda x:x['Frame']):\n",
    "        entry_list = []\n",
    "        for item in entry:\n",
    "            lst = list(item['BBOX'])\n",
    "            lst.extend([0, item['ID']])\n",
    "            entry_list.append(lst)\n",
    "        track_bbs_ids = Sorter.update(np.array(entry_list))\n",
    "        for objects in track_bbs_ids:\n",
    "            r0, c0, r1, c1, ID, label = objects.tolist()\n",
    "            for region in measure.regionprops(output[instance], color.rgb2gray(frames[instance])):\n",
    "                if region.label == label:\n",
    "                    this_normalized_moment = region.moments_normalized\n",
    "                    angle = np.degrees((np.arctan2(2*this_normalized_moment[1,1], this_normalized_moment[2,0] - this_normalized_moment[0,2]))/2)\n",
    "                    w = region.bbox[2] - region.bbox[0]\n",
    "                    h = region.bbox[3] - region.bbox[1]\n",
    "                    ar = w / float(h)\n",
    "                    tracked_bboxes.append({'Frame': instance, \n",
    "                                            'ID': int(label), \n",
    "                                            'Track ID': int(ID), \n",
    "                                            'BBOX': region.bbox,\n",
    "                                            'Angle': angle,\n",
    "                                            'Area': region.area,\n",
    "                                            'Aspect Ratio': ar, \n",
    "                                            'Eccentricity': region.eccentricity, \n",
    "                                            'Perimeter': region.perimeter})\n",
    "    tracked_dataframe = pd.DataFrame(tracked_bboxes)\n",
    "    super_output = []\n",
    "    if len(tracked_dataframe) == 0:\n",
    "        super_output.append({'File': None, 'Frame': None, 'Bounding Box': None})\n",
    "    else:\n",
    "        for tracks, track_df in tracked_dataframe.groupby('Track ID'):\n",
    "            current_track = track_df.loc[(track_df['Track ID'] == tracks), :]\n",
    "            with ChainedAssignment():\n",
    "                current_track['Rate of Change'] = current_track.loc[(current_track['Track ID'] == tracks), :]['Angle'].pct_change(5, fill_method = 'ffill') # 1 Tunable parameters (Periodicity for rate of change in angle)\n",
    "                current_track['Slip-Fall'] = np.where(current_track['Rate of Change'] < -10, 'Slip', 'Stand') # 1 Tunable Parameter (Hard Cutoff for % change in angle)\n",
    "            if len(current_track.loc[current_track['Slip-Fall'] == 'Slip']) != 0:\n",
    "                super_output.append({'Track ID': tracks, 'File': os.path.basename(path), 'Frame': current_track.loc[current_track['Slip-Fall'] == 'Slip'].iloc[0]['Frame'], 'Bounding Box': current_track.loc[current_track['Slip-Fall'] == 'Slip'].iloc[0]['BBOX']})\n",
    "            else:\n",
    "                super_output.append({'Track ID': None, 'File': None, 'Frame': None, 'Bounding Box': None})\n",
    "    df = pd.DataFrame(super_output)\n",
    "    df = df.dropna()\n",
    "    return df, tracked_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/slip-fall/fall-database/0034.mp4\n"
     ]
    }
   ],
   "source": [
    "# Debugging\n",
    "pathlist = sorted(glob.glob('../datasets/slip-fall/fall-database/*.mp4'))\n",
    "for path in pathlist[33:34]:\n",
    "    print(path)\n",
    "    fall_df, track_df = detect_fall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track ID</th>\n",
       "      <th>File</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Bounding Box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>(63, 327, 91, 349)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>(54, 220, 141, 333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>(46, 280, 143, 377)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>(64, 313, 99, 347)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>(201, 267, 303, 423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>(52, 257, 124, 417)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>164.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>(66, 393, 134, 417)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>165.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>(57, 321, 129, 402)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>179.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>(58, 345, 137, 365)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>197.0</td>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>(50, 215, 193, 283)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Track ID      File  Frame          Bounding Box\n",
       "0      151.0  0034.mp4   14.0    (63, 327, 91, 349)\n",
       "1      152.0  0034.mp4   15.0   (54, 220, 141, 333)\n",
       "2      153.0  0034.mp4   12.0   (46, 280, 143, 377)\n",
       "3      154.0  0034.mp4   13.0    (64, 313, 99, 347)\n",
       "4      155.0  0034.mp4   25.0  (201, 267, 303, 423)\n",
       "6      157.0  0034.mp4   33.0   (52, 257, 124, 417)\n",
       "11     164.0  0034.mp4   24.0   (66, 393, 134, 417)\n",
       "12     165.0  0034.mp4   36.0   (57, 321, 129, 402)\n",
       "23     179.0  0034.mp4   34.0   (58, 345, 137, 365)\n",
       "39     197.0  0034.mp4   44.0   (50, 215, 193, 283)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 308, 131, 370)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_df[(track_df['Track ID'] == 153) & (track_df['Frame'] >= 14)][['Frame', 'BBOX']].values.tolist()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "# writer = cv2.VideoWriter(\"./results/no-slip-videos/{}.mp4\".format(video), 0x7634706d, 5.0, max([x.shape for x in boundaries])[:-1][::-1])\n",
    "# for capture in boundaries:\n",
    "#     out_capture = (capture * 255).astype(np.uint8)\n",
    "#     writer.write(out_capture)\n",
    "# writer.release()\n",
    "\n",
    "# Add pixelwise outline + bounding box of fall detection when it happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall Database\n",
    "pathlist = glob.glob('../datasets/slip-fall/fall-database/*.mp4')\n",
    "falls = []\n",
    "for path in pathlist:\n",
    "    falls.append(detect_fall(path))\n",
    "flatten_fall = [x for x in falls for x in x]\n",
    "df = pd.DataFrame(flatten_fall)\n",
    "final = df.dropna()\n",
    "fall_table = final[['File', 'Frame']].groupby(['File']).agg(Falls = ('Frame','count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Fall Database\n",
    "pathlist = glob.glob('../datasets/slip-fall/no-fall-database/*.mp4')\n",
    "falls = []\n",
    "for path in pathlist:\n",
    "    falls.append(detect_fall(path))\n",
    "flatten_fall = [x for x in falls for x in x]\n",
    "df = pd.DataFrame(flatten_fall)\n",
    "final = df.dropna()\n",
    "final[['File', 'Frame']].groupby(['File']).agg(Falls = ('Frame','count')).reset_index()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7997ca2cf6f82a32cba4455fba40e779da088b6fcef0f47d94689f04f3d2f0e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('YOLACT': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
