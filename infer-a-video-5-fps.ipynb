{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    ██╗   ██╗ ██████╗ ██╗      █████╗  ██████╗████████╗\n",
    "    ╚██╗ ██╔╝██╔═══██╗██║     ██╔══██╗██╔════╝╚══██╔══╝\n",
    "     ╚████╔╝ ██║   ██║██║     ███████║██║        ██║   \n",
    "      ╚██╔╝  ██║   ██║██║     ██╔══██║██║        ██║   \n",
    "       ██║   ╚██████╔╝███████╗██║  ██║╚██████╗   ██║   \n",
    "       ╚═╝    ╚═════╝ ╚══════╝╚═╝  ╚═╝ ╚═════╝   ╚═╝ \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import VideoReaders, DetectorLoader\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from itertools import groupby\n",
    "import warnings\n",
    "from SORT.sort import *\n",
    "from skimage import measure, color, draw\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Identify True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600d270593794e2e8ca96dd4bf35f70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Fall?</th>\n",
       "      <th>Paths</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0009.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0010.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0011.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0012.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0013.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0014.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0015.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0016.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0017.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0018.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0019.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0020.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0021.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0022.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0023.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0024.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0025.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0026.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0028.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0029.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0030.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0031.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0032.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0033.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0034.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>../datasets/slip-fall/mladen-holdout/05-FPS/0....</td>\n",
       "      <td>Just Right.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File  Fall?                                              Paths  \\\n",
       "7   0009.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "8   0010.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "9   0011.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "10  0012.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "11  0013.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "12  0014.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "13  0015.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "14  0016.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "15  0017.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "16  0018.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "17  0019.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "18  0020.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "19  0021.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "20  0022.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "21  0023.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "22  0024.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "23  0025.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "24  0026.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "26  0028.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "27  0029.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "28  0030.mp4      1  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "29  0031.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "30  0032.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "31  0033.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "32  0034.mp4      0  ../datasets/slip-fall/mladen-holdout/05-FPS/0....   \n",
       "\n",
       "          Usage  \n",
       "7   Just Right.  \n",
       "8   Just Right.  \n",
       "9   Just Right.  \n",
       "10  Just Right.  \n",
       "11  Just Right.  \n",
       "12  Just Right.  \n",
       "13  Just Right.  \n",
       "14  Just Right.  \n",
       "15  Just Right.  \n",
       "16  Just Right.  \n",
       "17  Just Right.  \n",
       "18  Just Right.  \n",
       "19  Just Right.  \n",
       "20  Just Right.  \n",
       "21  Just Right.  \n",
       "22  Just Right.  \n",
       "23  Just Right.  \n",
       "24  Just Right.  \n",
       "26  Just Right.  \n",
       "27  Just Right.  \n",
       "28  Just Right.  \n",
       "29  Just Right.  \n",
       "30  Just Right.  \n",
       "31  Just Right.  \n",
       "32  Just Right.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truths = pd.read_csv('datasets/slip-fall/mladen-holdout/slip-fall-mladen-ground-truth.csv')\n",
    "dataset = []\n",
    "for flag, df in tqdm(ground_truths.groupby('Fall?')):\n",
    "    pathlist = [os.path.join(\n",
    "        '../datasets/slip-fall/mladen-holdout/05-FPS/0.25x/',\n",
    "        x\n",
    "    ) for x in df['File']]\n",
    "    df['Paths'] = pathlist\n",
    "    dataset.append(df)\n",
    "\n",
    "dataset = pd.concat(dataset)\n",
    "\n",
    "def check_video_length(x):\n",
    "    '''\n",
    "    Uses the VideoLoader to detect if the frames are too long for use in our dataset on a series of data in a dataframe. \n",
    "    '''\n",
    "    frame_provider = VideoReaders.VideoReader(x)\n",
    "    length, shape = frame_provider.properties()\n",
    "    if length > 100:\n",
    "        return \"Too Big.\"\n",
    "    else:\n",
    "        return \"Just Right.\"\n",
    "\n",
    "dataset['Usage'] = dataset['Paths'].apply(check_video_length)\n",
    "usable_data = dataset[(dataset['Usage'] == 'Just Right.')]\n",
    "display(usable_data.sort_values('File'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedAssignment:\n",
    "    def __init__(self, chained=None):\n",
    "        acceptable = [None, 'warn', 'raise']\n",
    "        assert chained in acceptable, \"chained must be in \" + str(acceptable)\n",
    "        self.swcw = chained\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.saved_swcw = pd.options.mode.chained_assignment\n",
    "        pd.options.mode.chained_assignment = self.swcw\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        pd.options.mode.chained_assignment = self.saved_swcw\n",
    "\n",
    "def instantaneous_time(x):\n",
    "    frame_interval = 0.2\n",
    "    return (x[1] - x[0]) * frame_interval\n",
    "\n",
    "def angular_displacement(x):\n",
    "    return (x[1] - x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load input video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model = DetectorLoader.YOLACT('./weights/slip-fall-chosen-weights/yolact_resnet50_432_74900.pth', threshold = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf015d06f4d4a28871fb68c1f7d202d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0009.mp4 is 84 frames.\n",
      "0009.mp4, chart complete!\n",
      "Output processed video for 0009.mp4\n",
      "0010.mp4 is 49 frames.\n",
      "0010.mp4, chart complete!\n",
      "Output processed video for 0010.mp4\n",
      "0011.mp4 is 90 frames.\n",
      "0011.mp4, chart complete!\n",
      "Output processed video for 0011.mp4\n",
      "0012.mp4 is 89 frames.\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(usable_data.groupby('Paths'))\n",
    "for path, _ in pbar:\n",
    "    frame_provider = VideoReaders.VideoReader(path)\n",
    "    length, shape = frame_provider.properties()\n",
    "    print('{} is {} frames.'.format(os.path.basename(path),length))\n",
    "\n",
    "    frames = []\n",
    "    inference = []\n",
    "    for frame in frame_provider:\n",
    "        frames.append(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        c, s, bb, ma = model.predict(frame[:,:,[2,1,0]])\n",
    "        idx = np.where(c == 0) # Person has a Class ID of 0\n",
    "        pixelwise_arrays = []\n",
    "        for item in idx:\n",
    "            for n, qq in enumerate(item):\n",
    "                pixelwise = np.zeros_like(ma[qq,...])\n",
    "                pixelwise = ma[qq,...].astype(np.uint8)\n",
    "                pixelwise[np.where(pixelwise == 1)] = n + 1\n",
    "                pixelwise_arrays.append(pixelwise)\n",
    "\n",
    "        filtered = []\n",
    "        for array in pixelwise_arrays:\n",
    "            if np.max(array) != 0:\n",
    "                filtered.append(array)\n",
    "\n",
    "        stacked = np.sum(filtered, axis = 0) # Will cause the array pixel values to increase in numerical value. This also maintains multiple people in the frame. \n",
    "        inference.append(stacked)\n",
    "\n",
    "    output = []\n",
    "    for arry in inference: # Check if the shape coming out of the model is OK.\n",
    "        if len(arry.shape) < 2:\n",
    "            output.append(np.zeros(shape).astype(np.uint8))\n",
    "        else:\n",
    "            output.append(arry)\n",
    "\n",
    "    def check(list1, val):\n",
    "        return(any(x < val for x in list1))\n",
    "\n",
    "    # IGNORE ZONES CODE: Remove anything that's not in the frame\n",
    "    for frame_position in range(0, length):\n",
    "        generated_image = np.zeros_like(output[frame_position])\n",
    "        for pixel in np.unique(output[frame_position]):\n",
    "            if pixel == 0: \n",
    "                pass\n",
    "            else:\n",
    "                ignore_perimeter = 25 # Tunable parameter for ignore zone\n",
    "                end_extent = (generated_image.shape[0] - ignore_perimeter, generated_image.shape[1] - ignore_perimeter)\n",
    "                perim_rr, perim_cc = draw.rectangle_perimeter(start = (ignore_perimeter, ignore_perimeter), end = end_extent)\n",
    "                rectangle_coords = np.stack((perim_rr, perim_cc), axis = 1)\n",
    "                generated_image[rectangle_coords[:,0], rectangle_coords[:,1]] = 1 # Debugging\n",
    "                for otherregion in measure.regionprops((output[frame_position] == pixel).astype(np.uint8)):\n",
    "                    mask_coordinates = otherregion.coords\n",
    "                    generated_image[mask_coordinates[:,0], mask_coordinates[:,1]] = 1\n",
    "                distances = cdist(mask_coordinates, rectangle_coords, metric = 'euclidean') # Compute the euclidean distance between points and imposed boundary \n",
    "                minimum_distance = np.min(distances, axis = 1).tolist()\n",
    "                integer_minimum_distances = [int(item) for item in minimum_distance]\n",
    "                if check(integer_minimum_distances, 1):\n",
    "                    output[frame_position][output[frame_position] == pixel] = 0\n",
    "\n",
    "    # Derive measurement of angles and link pixelwise masks using SORT\n",
    "    minimal_dictionary = []\n",
    "    for i in range(0, length):\n",
    "        for region in measure.regionprops(output[i], color.rgb2gray(frames[i])):\n",
    "            minimal_dictionary.append({\n",
    "                \"Frame\": i, \n",
    "                \"ID\": region.label, \n",
    "                \"BBOX\": region.bbox\n",
    "            })\n",
    "    tracked_bboxes = []\n",
    "    Sorter = Sort(max_age = 5, min_hits = 1, iou_threshold = 0.2) # 1 Tunable parameters for SORT\n",
    "    for instance, entry in groupby(minimal_dictionary, key = lambda x:x['Frame']):\n",
    "        entry_list = []\n",
    "        for item in entry:\n",
    "            lst = list(item['BBOX'])\n",
    "            lst.extend([0, item['ID']])\n",
    "            entry_list.append(lst)\n",
    "        track_bbs_ids = Sorter.update(np.array(entry_list))\n",
    "        for objects in track_bbs_ids:\n",
    "            r0, c0, r1, c1, ID, label = objects.tolist()\n",
    "            for region in measure.regionprops(output[instance], color.rgb2gray(frames[instance])):\n",
    "                if region.label == label:\n",
    "                    this_normalized_moment = region.moments_normalized\n",
    "                    angle = (np.arctan2(2*this_normalized_moment[1,1], this_normalized_moment[2,0] - this_normalized_moment[0,2]))/2 # Normalized image moments \n",
    "                    w = region.bbox[2] - region.bbox[0]\n",
    "                    h = region.bbox[3] - region.bbox[1]\n",
    "                    ar = w / float(h)\n",
    "                    tracked_bboxes.append({'Frame': instance, \n",
    "                                            'ID': int(label), \n",
    "                                            'Track ID': int(ID), \n",
    "                                            'BBOX': region.bbox,\n",
    "                                            'θ': angle,\n",
    "                                            'Area': region.area,\n",
    "                                            'Aspect Ratio': ar, \n",
    "                                            'Eccentricity': region.eccentricity, \n",
    "                                            'Perimeter': region.perimeter})\n",
    "    tracked_dataframe = pd.DataFrame(tracked_bboxes)\n",
    "    \n",
    "    # Calculate angular acceleration. \n",
    "    super_output = []\n",
    "    if len(tracked_dataframe) == 0:\n",
    "        super_output.append({'File': None, 'Frame': None, 'Bounding Box': None, 'ID': None, 'θ': None, 'dθ': None, 'Δt': None, '⍵': None, '⍵^2': None})\n",
    "    else:\n",
    "        for tracks, track_df in tracked_dataframe.groupby('Track ID'):\n",
    "            # TODO Might want to add an if statement to suppress tracks with length less than track age. \n",
    "            current_track = track_df.loc[(track_df['Track ID'] == tracks), :]\n",
    "            with ChainedAssignment():\n",
    "                current_track['dθ'] = current_track.loc[(current_track['Track ID'] == tracks), :]['θ'].rolling(window = 2).apply(angular_displacement, raw = True).fillna(0)\n",
    "                current_track['Δt'] = current_track.loc[(current_track['Track ID'] == tracks), :]['Frame'].rolling(window = 2).apply(instantaneous_time, raw = True).fillna(0).cumsum()\n",
    "                current_track['⍵'] = current_track.loc[(current_track['Track ID'] == tracks), :]['dθ'].diff() / current_track.loc[(current_track['Track ID'] == tracks), :]['Δt'].diff().fillna(0)\n",
    "                current_track['⍵^2'] = current_track.loc[(current_track['Track ID'] == tracks), :]['⍵'].diff() / current_track.loc[(current_track['Track ID'] == tracks), :]['Δt'].diff()\n",
    "                super_output.append(current_track)\n",
    "    fall_identities = pd.concat(super_output)\n",
    "\n",
    "    # Export plots. \n",
    "    try:\n",
    "        fall_identities = fall_identities.dropna()\n",
    "        df = pd.melt(fall_identities[['ID', 'Track ID', 'Frame', 'θ', 'dθ', 'Δt', '⍵', '⍵^2']], \n",
    "                id_vars = ['Track ID', 'Frame'], \n",
    "                value_vars = ['dθ', '⍵', '⍵^2'],\n",
    "                var_name = 'Parameter',\n",
    "                value_name = 'Value')\n",
    "        if len(np.unique(df['Track ID'])) > 1:\n",
    "            with sns.axes_style('whitegrid'):\n",
    "                sns.despine()\n",
    "                g = sns.relplot(data = df, x = 'Frame', y = 'Value', hue = 'Parameter', col = 'Track ID', kind = 'line', aspect = 1.5)\n",
    "                g.set(ylabel = 'θ (radians)', ylim = (-150, 150))\n",
    "            g.tight_layout()\n",
    "            g.savefig('datasets/slip-fall/mladen-holdout/charts/{}'.format(os.path.basename(path).replace('.mp4', '.png')), dpi = 300)\n",
    "            plt.close(g.fig)\n",
    "        else:\n",
    "            f,ax = plt.subplots(1)\n",
    "            with sns.axes_style('whitegrid'):\n",
    "                sns.despine()\n",
    "                sns.lineplot(data = df, x = 'Frame', y = 'Value', hue = 'Parameter', ax = ax)\n",
    "                ax.set(ylabel = 'θ (radians)', ylim = (-150, 150))\n",
    "            f.tight_layout()\n",
    "            f.savefig('datasets/slip-fall/mladen-holdout/charts/{}'.format(os.path.basename(path).replace('.mp4', '.png')), dpi = 300)\n",
    "            plt.close(f)\n",
    "        print('{}, chart complete!'.format(os.path.basename(path)))\n",
    "    except TypeError:\n",
    "        print('{} did not produce a chart.'.format(os.path.basename(path)))\n",
    "        continue\n",
    "\n",
    "    # Produce annotated video. \n",
    "    aggregate_bbox_df = []\n",
    "    fall_identities = fall_identities.dropna()\n",
    "    for track, data in fall_identities.groupby('Track ID'):\n",
    "        investigate_frame = data['Frame'].values\n",
    "        to_merge = tracked_dataframe[(tracked_dataframe['Track ID'] == track) & (tracked_dataframe['Frame'].isin(investigate_frame))][['Frame', 'ID', 'Track ID', 'BBOX']]\n",
    "        cv2_dataframe = data.merge(to_merge[['Frame', 'ID', 'Track ID', 'BBOX']], on = ['Frame', 'ID', 'Track ID', 'BBOX'])\n",
    "        aggregate_bbox_df.append(cv2_dataframe)\n",
    "\n",
    "        final_frames = []\n",
    "        if len(aggregate_bbox_df) == 0:\n",
    "            final_frames.append(frames)\n",
    "        else:\n",
    "            concat_bbox_df = pd.concat(aggregate_bbox_df)\n",
    "            bbox_dictionary = concat_bbox_df.groupby('Frame').agg(tuple).applymap(list).reset_index()\n",
    "            cv2_final_xx = pd.concat([bbox_dictionary.set_index('Frame').reindex(range(0, bbox_dictionary.Frame.min())).ffill().reset_index(), bbox_dictionary])\n",
    "            cv2_final_dictionary = cv2_final_xx.set_index('Frame').reindex(range(0, len(frames)), fill_value = np.NaN).reset_index()\n",
    "\n",
    "            for frame, info in cv2_final_dictionary.groupby('Frame'):\n",
    "                    if info.loc[info['Frame'] == frame]['Track ID'].isnull().values:\n",
    "                        final_frames.append(frames[frame])\n",
    "                    else:\n",
    "                        for track, acceleration, bounds in zip(info['Track ID'], info['⍵^2'], info['BBOX']):\n",
    "                                for t, acc, tuple_object in zip(track, acceleration, bounds):\n",
    "                                        text = '{:.0f} radians/s^2'.format(int(abs(acc)))\n",
    "                                        x = tuple_object[0]\n",
    "                                        y = tuple_object[1]\n",
    "                                        w = tuple_object[2] - tuple_object[0]\n",
    "                                        h = tuple_object[3] - tuple_object[1]\n",
    "                                        if 0 < abs(acc) < 10:\n",
    "                                                color_value = (118,238,0)\n",
    "                                        elif 11 < abs(acc) < 50:\n",
    "                                                color_value = (255,215,0)\n",
    "                                        elif abs(acc) > 51: \n",
    "                                                color_value = (255,48,48)\n",
    "                                        else:\n",
    "                                                pass\n",
    "                                        image_output = cv2.rectangle(frames[frame], (y,x), (y + h, x + w), color_value, 1)\n",
    "                                        image_output = cv2.putText(image_output, str(text), (y, x - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color_value, 2)\n",
    "                        final_frames.append(image_output)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv2.VideoWriter(\"datasets/slip-fall/mladen-holdout/videos/{}\".format(os.path.basename(path)), 0x7634706d, 5.0, max([x.shape for x in final_frames])[:-1][::-1])\n",
    "    for capture in final_frames:\n",
    "        out_capture = cv2.cvtColor(capture, cv2.COLOR_BGR2RGB)\n",
    "        writer.write(out_capture)\n",
    "    writer.release()\n",
    "    print('Output processed video for {}'.format(os.path.basename(path)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7997ca2cf6f82a32cba4455fba40e779da088b6fcef0f47d94689f04f3d2f0e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('YOLACT': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
