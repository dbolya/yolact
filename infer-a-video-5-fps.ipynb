{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    ██╗   ██╗ ██████╗ ██╗      █████╗  ██████╗████████╗\n",
    "    ╚██╗ ██╔╝██╔═══██╗██║     ██╔══██╗██╔════╝╚══██╔══╝\n",
    "     ╚████╔╝ ██║   ██║██║     ███████║██║        ██║   \n",
    "      ╚██╔╝  ██║   ██║██║     ██╔══██║██║        ██║   \n",
    "       ██║   ╚██████╔╝███████╗██║  ██║╚██████╗   ██║   \n",
    "       ╚═╝    ╚═════╝ ╚══════╝╚═╝  ╚═╝ ╚═════╝   ╚═╝ \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import VideoReaders, DetectorLoader\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from skimage import segmentation\n",
    "from itertools import groupby\n",
    "import random, warnings\n",
    "from SORT.sort import *\n",
    "from skimage import measure, color, segmentation, draw\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Identify True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = pd.read_csv('datasets/slip-fall/mladen-holdout/slip-fall-mladen-ground-truth.csv')\n",
    "dataset = []\n",
    "for flag, df in ground_truths.groupby('Fall?'):\n",
    "    pathlist = [os.path.join(\n",
    "        '../datasets/slip-fall/mladen-holdout/05-FPS/0.25x/',\n",
    "        x\n",
    "    ) for x in df['File']]\n",
    "    df['Paths'] = pathlist\n",
    "    dataset.append(df)\n",
    "\n",
    "dataset = pd.concat(dataset)\n",
    "\n",
    "def check_video_length(x):\n",
    "    '''\n",
    "    Uses the VideoLoader to detect if the frames are too long for use in our dataset on a series of data in a dataframe. \n",
    "    '''\n",
    "    frame_provider = VideoReaders.VideoReader(x)\n",
    "    length, shape = frame_provider.properties()\n",
    "    if length > 100:\n",
    "        return \"Too Big.\"\n",
    "    else:\n",
    "        return \"Just Right.\"\n",
    "\n",
    "dataset['Usage'] = dataset['Paths'].apply(check_video_length)\n",
    "usable_data = dataset[(dataset['Usage'] == 'Just Right.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedAssignment:\n",
    "    def __init__(self, chained=None):\n",
    "        acceptable = [None, 'warn', 'raise']\n",
    "        assert chained in acceptable, \"chained must be in \" + str(acceptable)\n",
    "        self.swcw = chained\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.saved_swcw = pd.options.mode.chained_assignment\n",
    "        pd.options.mode.chained_assignment = self.swcw\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        pd.options.mode.chained_assignment = self.saved_swcw\n",
    "\n",
    "def instantaneous_time(x):\n",
    "    frame_interval = 0.2\n",
    "    return (x[1] - x[0]) * frame_interval\n",
    "\n",
    "def angular_displacement(x):\n",
    "    return (x[1] - x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load input video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model = DetectorLoader.YOLACT('./weights/slip-fall-chosen-weights/yolact_resnet50_432_74900.pth', threshold = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0009.mp4 is 84 frames.\n",
      "0010.mp4 is 49 frames.\n",
      "0011.mp4 is 90 frames.\n",
      "0012.mp4 is 89 frames.\n",
      "0013.mp4 is 91 frames.\n",
      "0014.mp4 is 80 frames.\n",
      "0015.mp4 is 75 frames.\n",
      "0016.mp4 is 60 frames.\n",
      "0017.mp4 is 63 frames.\n",
      "0017.mp4 did not produce a chart.\n",
      "0018.mp4 is 62 frames.\n",
      "0019.mp4 is 75 frames.\n",
      "0020.mp4 is 80 frames.\n",
      "0021.mp4 is 60 frames.\n",
      "0022.mp4 is 69 frames.\n",
      "0023.mp4 is 55 frames.\n",
      "0024.mp4 is 56 frames.\n",
      "0025.mp4 is 59 frames.\n",
      "0026.mp4 is 61 frames.\n",
      "0028.mp4 is 43 frames.\n",
      "0029.mp4 is 53 frames.\n",
      "0030.mp4 is 38 frames.\n",
      "0031.mp4 is 44 frames.\n",
      "0032.mp4 is 24 frames.\n",
      "0033.mp4 is 24 frames.\n",
      "0034.mp4 is 23 frames.\n"
     ]
    }
   ],
   "source": [
    "for path, _ in usable_data.groupby('Paths'):\n",
    "    frame_provider = VideoReaders.VideoReader(path)\n",
    "    length, shape = frame_provider.properties()\n",
    "    print('{} is {} frames.'.format(os.path.basename(path),length))\n",
    "\n",
    "    frames = []\n",
    "    inference = []\n",
    "    for frame in frame_provider:\n",
    "        frames.append(frame[:,:,[2,1,0]])\n",
    "        c, s, bb, ma = model.predict(frame[:,:,[2,1,0]])\n",
    "        idx = np.where(c == 0) # Person has a Class ID of 0\n",
    "        pixelwise_arrays = []\n",
    "        for item in idx:\n",
    "            for n, qq in enumerate(item):\n",
    "                pixelwise = np.zeros_like(ma[qq,...])\n",
    "                pixelwise = ma[qq,...].astype(np.uint8)\n",
    "                pixelwise[np.where(pixelwise == 1)] = n + 1\n",
    "                pixelwise_arrays.append(pixelwise)\n",
    "\n",
    "        filtered = []\n",
    "        for array in pixelwise_arrays:\n",
    "            if np.max(array) != 0:\n",
    "                filtered.append(array)\n",
    "\n",
    "        stacked = np.sum(filtered, axis = 0) # Will cause the array pixel values to increase in numerical value. This also maintains multiple people in the frame. \n",
    "        inference.append(stacked)\n",
    "\n",
    "    output = []\n",
    "    for arry in inference: # Check if the shape coming out of the model is OK.\n",
    "        if len(arry.shape) < 2:\n",
    "            output.append(np.zeros(shape).astype(np.uint8))\n",
    "        else:\n",
    "            output.append(arry)\n",
    "\n",
    "    def check(list1, val):\n",
    "        return(any(x < val for x in list1))\n",
    "\n",
    "    # Remove anything that's not in the frame\n",
    "    for frame_position in range(0, length):\n",
    "        generated_image = np.zeros_like(output[frame_position])\n",
    "        for pixel in np.unique(output[frame_position]):\n",
    "            if pixel == 0: \n",
    "                pass\n",
    "            else:\n",
    "                ignore_perimeter = 25 # Tunable parameter for ignore zone\n",
    "                end_extent = (generated_image.shape[0] - ignore_perimeter, generated_image.shape[1] - ignore_perimeter)\n",
    "                perim_rr, perim_cc = draw.rectangle_perimeter(start = (ignore_perimeter, ignore_perimeter), end = end_extent)\n",
    "                rectangle_coords = np.stack((perim_rr, perim_cc), axis = 1)\n",
    "                generated_image[rectangle_coords[:,0], rectangle_coords[:,1]] = 1 # Debugging\n",
    "                for otherregion in measure.regionprops((output[frame_position] == pixel).astype(np.uint8)):\n",
    "                    mask_coordinates = otherregion.coords\n",
    "                    generated_image[mask_coordinates[:,0], mask_coordinates[:,1]] = 1\n",
    "                distances = cdist(mask_coordinates, rectangle_coords, metric = 'euclidean') # Compute the euclidean distance between points and imposed boundary \n",
    "                minimum_distance = np.min(distances, axis = 1).tolist()\n",
    "                integer_minimum_distances = [int(item) for item in minimum_distance]\n",
    "                if check(integer_minimum_distances, 1):\n",
    "                    output[frame_position][output[frame_position] == pixel] = 0\n",
    "\n",
    "    # Derive measurement of angles\n",
    "    minimal_dictionary = []\n",
    "    for i in range(0, length):\n",
    "        for region in measure.regionprops(output[i], color.rgb2gray(frames[i])):\n",
    "            minimal_dictionary.append({\n",
    "                \"Frame\": i, \n",
    "                \"ID\": region.label, \n",
    "                \"BBOX\": region.bbox\n",
    "            })\n",
    "    tracked_bboxes = []\n",
    "    Sorter = Sort(max_age = 5, min_hits = 1, iou_threshold = 0.2) # 1 Tunable parameters for SORT\n",
    "    for instance, entry in groupby(minimal_dictionary, key = lambda x:x['Frame']):\n",
    "        entry_list = []\n",
    "        for item in entry:\n",
    "            lst = list(item['BBOX'])\n",
    "            lst.extend([0, item['ID']])\n",
    "            entry_list.append(lst)\n",
    "        track_bbs_ids = Sorter.update(np.array(entry_list))\n",
    "        for objects in track_bbs_ids:\n",
    "            r0, c0, r1, c1, ID, label = objects.tolist()\n",
    "            for region in measure.regionprops(output[instance], color.rgb2gray(frames[instance])):\n",
    "                if region.label == label:\n",
    "                    this_normalized_moment = region.moments_normalized\n",
    "                    angle = (np.arctan2(2*this_normalized_moment[1,1], this_normalized_moment[2,0] - this_normalized_moment[0,2]))/2 # Normalized image moments \n",
    "                    w = region.bbox[2] - region.bbox[0]\n",
    "                    h = region.bbox[3] - region.bbox[1]\n",
    "                    ar = w / float(h)\n",
    "                    tracked_bboxes.append({'Frame': instance, \n",
    "                                            'ID': int(label), \n",
    "                                            'Track ID': int(ID), \n",
    "                                            'BBOX': region.bbox,\n",
    "                                            'θ': angle,\n",
    "                                            'Area': region.area,\n",
    "                                            'Aspect Ratio': ar, \n",
    "                                            'Eccentricity': region.eccentricity, \n",
    "                                            'Perimeter': region.perimeter})\n",
    "    tracked_dataframe = pd.DataFrame(tracked_bboxes)\n",
    "\n",
    "    super_output = []\n",
    "    if len(tracked_dataframe) == 0:\n",
    "        super_output.append({'File': None, 'Frame': None, 'Bounding Box': None, 'ID': None, 'θ': None, 'dθ': None, 'Δt': None, '⍵': None, '⍵^2': None})\n",
    "    else:\n",
    "        for tracks, track_df in tracked_dataframe.groupby('Track ID'):\n",
    "            # TODO Might want to add an if statement to suppress tracks with length less than track age. \n",
    "            current_track = track_df.loc[(track_df['Track ID'] == tracks), :]\n",
    "            with ChainedAssignment():\n",
    "                current_track['dθ'] = current_track.loc[(current_track['Track ID'] == tracks), :]['θ'].rolling(window = 2).apply(angular_displacement, raw = True).fillna(0)\n",
    "                current_track['Δt'] = current_track.loc[(current_track['Track ID'] == tracks), :]['Frame'].rolling(window = 2).apply(instantaneous_time, raw = True).fillna(0).cumsum()\n",
    "                current_track['⍵'] = current_track.loc[(current_track['Track ID'] == tracks), :]['dθ'].diff() / current_track.loc[(current_track['Track ID'] == tracks), :]['Δt'].diff().fillna(0)\n",
    "                current_track['⍵^2'] = current_track.loc[(current_track['Track ID'] == tracks), :]['⍵'].diff() / current_track.loc[(current_track['Track ID'] == tracks), :]['Δt'].diff()\n",
    "                super_output.append(current_track)\n",
    "\n",
    "    test = super_output[0]\n",
    "    try:\n",
    "        df = pd.melt(test[['ID', 'Frame', 'θ', 'dθ', 'Δt', '⍵', '⍵^2']], \n",
    "                id_vars = ['Frame'], \n",
    "                value_vars = ['dθ', '⍵', '⍵^2'],\n",
    "                var_name = 'Parameter',\n",
    "                value_name = 'Value')\n",
    "        f,ax = plt.subplots(1)\n",
    "        with sns.axes_style('whitegrid'):\n",
    "            sns.despine()\n",
    "            sns.lineplot(data = df, x = 'Frame', y = 'Value', hue = 'Parameter', ax = ax)\n",
    "            ax.set(ylabel = 'θ (radians)', ylim = (-50, 50))\n",
    "        f.tight_layout()\n",
    "        f.savefig('Chart-{}'.format(os.path.basename(path).replace('.mp4', '.png')), dpi = 300)\n",
    "        plt.close(f)\n",
    "    except TypeError:\n",
    "        print('{} did not produce a chart.'.format(os.path.basename(path)))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create segmentation boundary mask for printout\n",
    "# if len(output) != len(frames):\n",
    "#     raise ValueError(\"Frame Lengths are off.\")\n",
    "# boundaries = []\n",
    "# for im, mask in zip(frames, output):\n",
    "#     boundaries.append(segmentation.mark_boundaries(im, mask, mode = 'thick', color = (0,1,0)))\n",
    "\n",
    "# # Create matplotlib. \n",
    "# columns = 8\n",
    "# rows, r = divmod(length, columns)\n",
    "# if r:\n",
    "#     rows += 1\n",
    "# f, ax = plt.subplots(rows, columns, figsize = (50,60))\n",
    "# ax = ax.flatten()\n",
    "# for n in range(0, length):\n",
    "#     ax[n].imshow(boundaries[n], aspect = 'auto')\n",
    "#     current_frame = str(n)\n",
    "#     ax[n].set(title = 'Frame {}'.format(current_frame.zfill(4)))\n",
    "#     ax[n].axis('off')\n",
    "# f.tight_layout()\n",
    "# f.savefig('{}.png'.format(os.path.basename(path).replace('.mp4', '')), dpi = 100)\n",
    "# plt.close(f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7997ca2cf6f82a32cba4455fba40e779da088b6fcef0f47d94689f04f3d2f0e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('YOLACT': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
